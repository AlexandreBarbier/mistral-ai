/*
 * Mistral AI API
 *
 * Our Chat Completion and Embeddings APIs specification. Create your account on [La Plateforme](https://console.mistral.ai) to get access and read the [docs](https://docs.mistral.ai) to learn how to use it.
 *
 * The version of the OpenAPI document: 0.0.2
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct ChatCompletionChoice {
    #[serde(rename = "index")]
    pub index: i32,
    #[serde(rename = "message")]
    pub message: models::AssistantMessage,
    #[serde(rename = "finish_reason")]
    pub finish_reason: FinishReason,
}

impl ChatCompletionChoice {
    pub fn new(index: i32, message: models::AssistantMessage, finish_reason: FinishReason) -> ChatCompletionChoice {
        ChatCompletionChoice {
            index,
            message,
            finish_reason,
        }
    }
}
/// 
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum FinishReason {
    #[serde(rename = "stop")]
    Stop,
    #[serde(rename = "length")]
    Length,
    #[serde(rename = "model_length")]
    ModelLength,
    #[serde(rename = "error")]
    Error,
    #[serde(rename = "tool_calls")]
    ToolCalls,
}

impl Default for FinishReason {
    fn default() -> FinishReason {
        Self::Stop
    }
}

