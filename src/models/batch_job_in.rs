/*
 * Mistral AI API
 *
 * Our Chat Completion and Embeddings APIs specification. Create your account on [La Plateforme](https://console.mistral.ai) to get access and read the [docs](https://docs.mistral.ai) to learn how to use it.
 *
 * The version of the OpenAPI document: 0.0.2
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct BatchJobIn {
    #[serde(rename = "input_files")]
    pub input_files: Vec<uuid::Uuid>,
    #[serde(rename = "endpoint")]
    pub endpoint: models::ApiEndpoint,
    #[serde(rename = "model")]
    pub model: String,
    #[serde(rename = "metadata", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub metadata: Option<Option<std::collections::HashMap<String, String>>>,
    #[serde(rename = "timeout_hours", skip_serializing_if = "Option::is_none")]
    pub timeout_hours: Option<i32>,
}

impl BatchJobIn {
    pub fn new(input_files: Vec<uuid::Uuid>, endpoint: models::ApiEndpoint, model: String) -> BatchJobIn {
        BatchJobIn {
            input_files,
            endpoint,
            model,
            metadata: None,
            timeout_hours: None,
        }
    }
}

