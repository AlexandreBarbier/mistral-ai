/*
 * Mistral AI API
 *
 * Our Chat Completion and Embeddings APIs specification. Create your account on [La Plateforme](https://console.mistral.ai) to get access and read the [docs](https://docs.mistral.ai) to learn how to use it.
 *
 * The version of the OpenAPI document: 0.0.2
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// TrainingParametersIn : The fine-tuning hyperparameter settings used in a fine-tune job.
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct TrainingParametersIn {
    #[serde(rename = "training_steps", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub training_steps: Option<Option<i32>>,
    /// A parameter describing how much to adjust the pre-trained model's weights in response to the estimated error each time the weights are updated during the fine-tuning process.
    #[serde(rename = "learning_rate", skip_serializing_if = "Option::is_none")]
    pub learning_rate: Option<f64>,
    #[serde(rename = "weight_decay", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub weight_decay: Option<Option<f64>>,
    #[serde(rename = "warmup_fraction", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub warmup_fraction: Option<Option<f64>>,
    #[serde(rename = "epochs", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub epochs: Option<Option<f64>>,
    #[serde(rename = "fim_ratio", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub fim_ratio: Option<Option<f64>>,
    #[serde(rename = "seq_len", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub seq_len: Option<Option<i32>>,
}

impl TrainingParametersIn {
    /// The fine-tuning hyperparameter settings used in a fine-tune job.
    pub fn new() -> TrainingParametersIn {
        TrainingParametersIn {
            training_steps: None,
            learning_rate: None,
            weight_decay: None,
            warmup_fraction: None,
            epochs: None,
            fim_ratio: None,
            seq_len: None,
        }
    }
}

